Warming up PyWSD (takes ~10 secs)... Loading the LM will be faster if you build a binary file.
Reading /remote-home/***/Code/NLP/EPDA/lms/offense.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Simple Test
['thusly cute the little baby is crying!', 'So cute the little baby is crying!']
LR= 5e-05
Start to read:  new_data/sentiment/train_1.txt
Load Over, Find:  153  datas.
Start to read:  new_data/sentiment/test.txt
Load Over, Find:  3027  datas.
took 5.79877781867981 secs.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Bert Tokenizer
Update EPOCHES to 16
Start to update Dataset
?? 2295 2295 2295
Before 153
Start Update Dataset, Find  153 datas.
Update Dataset Finish, Find  2295 datas.
< Update Done.
After 2295
start to extract something
torch.Size([2295, 3072]) 2295
Error Rate EPida0.0153 EDA0.0305 CEM0.0065 REM0.0675
Distance EPida0.0078 EDA0.0054 CEM0.0025 REM0.0121
> Done. Model Training
