Warming up PyWSD (takes ~10 secs)... Loading the LM will be faster if you build a binary file.
Reading /remote-home/***/Code/NLP/EPDA/lms/sentiment.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Simple Test
['thusly cute the little baby is crying!', 'So cute the little baby is crying!']
LR= 5e-05
Start to read:  new_data/sentiment/train_10.txt
Load Over, Find:  1514  datas.
Start to read:  new_data/sentiment/test.txt
Load Over, Find:  3027  datas.
took 6.893878936767578 secs.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Loading the LM will be faster if you build a binary file.
Reading /remote-home/***/Code/NLP/EPDA/lms/sentiment.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Update EPOCHES to 16
Start to update Dataset
Start to calculate PPL Score.
PPL Score 66.86463311930764
